{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60031261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Allows to get the module in utils\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "\n",
    "from utils.load import load_data\n",
    "from utils.preprocessing import preprocess\n",
    "from utils.split import split_data\n",
    "from utils.seed_definition import set_seed\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "import optuna\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.metrics import roc_auc_score, recall_score\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2392c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d0c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "# Split and preprocess datas set\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "X_train_processed, X_test_processed, X_val_processed, y_test_encoding, y_train_encoded, y_val_encoding, pipeline, le = preprocess(X_train, X_val, X_test, y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d5b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dense = X_train_processed.toarray() if hasattr(X_train_processed, \"toarray\") else X_train_processed\n",
    "X_val_dense = X_val_processed.toarray() if hasattr(X_val_processed, \"toarray\") else X_val_processed\n",
    "X_test_dense = X_test_processed.toarray() if hasattr(X_test_processed, \"toarray\") else X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08fc7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vector = y_train_encoded.reshape(-1)\n",
    "y_val_vector = y_val_encoding.reshape(-1)\n",
    "y_test_vector = y_test_encoding.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec1e3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 09:28:25.327345: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-05-26 09:28:25.327461: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-05-26 09:28:25.327488: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: utilisateur-ThinkPad-P53\n",
      "2025-05-26 09:28:25.327503: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: utilisateur-ThinkPad-P53\n",
      "2025-05-26 09:28:25.327769: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 550.144.3\n",
      "2025-05-26 09:28:25.327839: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 550.144.3\n",
      "2025-05-26 09:28:25.327849: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 550.144.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,209</span> (24.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,209\u001b[0m (24.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,209</span> (24.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,209\u001b[0m (24.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = X_train_dense.shape[1]\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_dim,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'recall', 'auc']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d561c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints/churn_models.keras\"\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',  \n",
    "    save_best_only=True,# sauvegarde le modèle qui maximise l’accuracy de validation\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961eff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m246/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7725 - auc: 0.7846 - loss: 0.4649 - recall: 0.3828\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78971, saving model to checkpoints/churn_models.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7743 - auc: 0.7888 - loss: 0.4628 - recall: 0.3956 - val_accuracy: 0.7897 - val_auc: 0.8355 - val_loss: 0.4490 - val_recall: 0.3579\n",
      "Epoch 2/20\n",
      "\u001b[1m253/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - auc: 0.8376 - loss: 0.4196 - recall: 0.4904  \n",
      "Epoch 2: val_accuracy improved from 0.78971 to 0.79148, saving model to checkpoints/churn_models.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7981 - auc: 0.8374 - loss: 0.4206 - recall: 0.4919 - val_accuracy: 0.7915 - val_auc: 0.8371 - val_loss: 0.4438 - val_recall: 0.3512\n",
      "Epoch 3/20\n",
      "\u001b[1m235/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8030 - auc: 0.8409 - loss: 0.4142 - recall: 0.4517\n",
      "Epoch 3: val_accuracy improved from 0.79148 to 0.79503, saving model to checkpoints/churn_models.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8017 - auc: 0.8406 - loss: 0.4159 - recall: 0.4543 - val_accuracy: 0.7950 - val_auc: 0.8392 - val_loss: 0.4381 - val_recall: 0.3612\n",
      "Epoch 4/20\n",
      "\u001b[1m244/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8044 - auc: 0.8448 - loss: 0.4099 - recall: 0.4448\n",
      "Epoch 4: val_accuracy did not improve from 0.79503\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - auc: 0.8447 - loss: 0.4111 - recall: 0.4473 - val_accuracy: 0.7862 - val_auc: 0.8373 - val_loss: 0.4426 - val_recall: 0.3144\n",
      "Epoch 5/20\n",
      "\u001b[1m258/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.8069 - auc: 0.8485 - loss: 0.4057 - recall: 0.4601\n",
      "Epoch 5: val_accuracy did not improve from 0.79503\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8063 - auc: 0.8483 - loss: 0.4066 - recall: 0.4619 - val_accuracy: 0.7950 - val_auc: 0.8392 - val_loss: 0.4417 - val_recall: 0.3512\n",
      "Epoch 6/20\n",
      "\u001b[1m243/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8087 - auc: 0.8513 - loss: 0.4000 - recall: 0.4789\n",
      "Epoch 6: val_accuracy improved from 0.79503 to 0.79681, saving model to checkpoints/churn_models.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - auc: 0.8510 - loss: 0.4016 - recall: 0.4799 - val_accuracy: 0.7968 - val_auc: 0.8344 - val_loss: 0.4439 - val_recall: 0.3679\n",
      "Epoch 7/20\n",
      "\u001b[1m244/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8146 - auc: 0.8536 - loss: 0.3993 - recall: 0.4828\n",
      "Epoch 7: val_accuracy improved from 0.79681 to 0.80213, saving model to checkpoints/churn_models.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8135 - auc: 0.8534 - loss: 0.4005 - recall: 0.4839 - val_accuracy: 0.8021 - val_auc: 0.8351 - val_loss: 0.4377 - val_recall: 0.4381\n",
      "Epoch 8/20\n",
      "\u001b[1m246/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8217 - auc: 0.8584 - loss: 0.3932 - recall: 0.5031\n",
      "Epoch 8: val_accuracy did not improve from 0.80213\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8204 - auc: 0.8579 - loss: 0.3948 - recall: 0.5029 - val_accuracy: 0.7986 - val_auc: 0.8354 - val_loss: 0.4376 - val_recall: 0.4214\n",
      "Epoch 9/20\n",
      "\u001b[1m245/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8186 - auc: 0.8592 - loss: 0.3926 - recall: 0.4877\n",
      "Epoch 9: val_accuracy did not improve from 0.80213\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8173 - auc: 0.8588 - loss: 0.3941 - recall: 0.4891 - val_accuracy: 0.8021 - val_auc: 0.8326 - val_loss: 0.4386 - val_recall: 0.4281\n",
      "Epoch 10/20\n",
      "\u001b[1m253/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8195 - auc: 0.8607 - loss: 0.3900 - recall: 0.4973\n",
      "Epoch 10: val_accuracy did not improve from 0.80213\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8183 - auc: 0.8604 - loss: 0.3913 - recall: 0.4977 - val_accuracy: 0.7977 - val_auc: 0.8305 - val_loss: 0.4431 - val_recall: 0.3880\n",
      "Epoch 11/20\n",
      "\u001b[1m236/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8239 - auc: 0.8647 - loss: 0.3839 - recall: 0.5036\n",
      "Epoch 11: val_accuracy did not improve from 0.80213\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8221 - auc: 0.8642 - loss: 0.3860 - recall: 0.5044 - val_accuracy: 0.7853 - val_auc: 0.8168 - val_loss: 0.4748 - val_recall: 0.3913\n",
      "Epoch 12/20\n",
      "\u001b[1m261/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8177 - auc: 0.8665 - loss: 0.3833 - recall: 0.5045\n",
      "Epoch 12: val_accuracy did not improve from 0.80213\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8171 - auc: 0.8666 - loss: 0.3840 - recall: 0.5052 - val_accuracy: 0.7933 - val_auc: 0.8169 - val_loss: 0.4756 - val_recall: 0.4247\n",
      "Epoch 13/20\n",
      "\u001b[1m245/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8204 - auc: 0.8678 - loss: 0.3807 - recall: 0.5197\n",
      "Epoch 13: val_accuracy did not improve from 0.80213\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8196 - auc: 0.8676 - loss: 0.3821 - recall: 0.5205 - val_accuracy: 0.7995 - val_auc: 0.8197 - val_loss: 0.4628 - val_recall: 0.4147\n",
      "Epoch 14/20\n",
      "\u001b[1m266/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8234 - auc: 0.8697 - loss: 0.3791 - recall: 0.5107\n",
      "Epoch 14: val_accuracy improved from 0.80213 to 0.80302, saving model to checkpoints/churn_models.keras\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8231 - auc: 0.8697 - loss: 0.3795 - recall: 0.5118 - val_accuracy: 0.8030 - val_auc: 0.8109 - val_loss: 0.4940 - val_recall: 0.4682\n",
      "Epoch 15/20\n",
      "\u001b[1m236/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8237 - auc: 0.8746 - loss: 0.3716 - recall: 0.5045\n",
      "Epoch 15: val_accuracy did not improve from 0.80302\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8222 - auc: 0.8743 - loss: 0.3735 - recall: 0.5059 - val_accuracy: 0.7995 - val_auc: 0.8246 - val_loss: 0.4653 - val_recall: 0.4582\n",
      "Epoch 16/20\n",
      "\u001b[1m249/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8236 - auc: 0.8765 - loss: 0.3694 - recall: 0.5214\n",
      "Epoch 16: val_accuracy did not improve from 0.80302\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8231 - auc: 0.8764 - loss: 0.3705 - recall: 0.5235 - val_accuracy: 0.7986 - val_auc: 0.8103 - val_loss: 0.4869 - val_recall: 0.4548\n",
      "Epoch 17/20\n",
      "\u001b[1m240/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8243 - auc: 0.8797 - loss: 0.3659 - recall: 0.5293\n",
      "Epoch 17: val_accuracy did not improve from 0.80302\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8242 - auc: 0.8795 - loss: 0.3672 - recall: 0.5333 - val_accuracy: 0.7968 - val_auc: 0.8127 - val_loss: 0.5017 - val_recall: 0.4381\n",
      "Epoch 18/20\n",
      "\u001b[1m281/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8198 - auc: 0.8793 - loss: 0.3663 - recall: 0.5207\n",
      "Epoch 18: val_accuracy did not improve from 0.80302\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8198 - auc: 0.8793 - loss: 0.3663 - recall: 0.5209 - val_accuracy: 0.7844 - val_auc: 0.8124 - val_loss: 0.5108 - val_recall: 0.4448\n",
      "Epoch 19/20\n",
      "\u001b[1m247/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8223 - auc: 0.8822 - loss: 0.3628 - recall: 0.5113\n",
      "Epoch 19: val_accuracy did not improve from 0.80302\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8224 - auc: 0.8822 - loss: 0.3636 - recall: 0.5153 - val_accuracy: 0.7941 - val_auc: 0.8065 - val_loss: 0.5098 - val_recall: 0.4515\n",
      "Epoch 20/20\n",
      "\u001b[1m243/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8245 - auc: 0.8856 - loss: 0.3578 - recall: 0.5416\n",
      "Epoch 20: val_accuracy did not improve from 0.80302\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8247 - auc: 0.8855 - loss: 0.3590 - recall: 0.5438 - val_accuracy: 0.7799 - val_auc: 0.8107 - val_loss: 0.5105 - val_recall: 0.4682\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_dense, y_train_vector,\n",
    "    validation_data=(X_val_dense, y_val_vector),\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    "    callbacks=[model_ckpt],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d23d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    n_units = trial.suggest_int('n_units', 32, 128, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
    "\n",
    "    # Optimizer mapping\n",
    "    optimizer = {\n",
    "        'adam': Adam(learning_rate=learning_rate),\n",
    "        'rmsprop': RMSprop(learning_rate=learning_rate)\n",
    "    }[optimizer_name]\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_vector),\n",
    "        y=y_train_vector\n",
    "    )\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Build model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(X_train_dense.shape[1],)))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dense(n_units, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['recall']\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_auc', mode='max', patience=5,\n",
    "        restore_best_weights=True, verbose=0\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    model.fit(\n",
    "        X_train_dense, y_train_vector,\n",
    "        validation_data=(X_val_dense, y_val_vector),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred_proba = model.predict(X_val_dense)\n",
    "    auc = roc_auc_score(y_val_vector, y_pred_proba)\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1eefe050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:29:34,995] A new study created in RDB with name: test_seed\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:29:41,921] Trial 0 finished with value: 0.8449339989982713 and parameters: {'learning_rate': 0.0001329291894316216, 'batch_size': 16, 'epochs': 16, 'n_layers': 1, 'n_units': 32, 'dropout_rate': 0.4330880728874676, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.8449339989982713.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:29:51,220] Trial 1 finished with value: 0.8262323687654501 and parameters: {'learning_rate': 0.00314288089084011, 'batch_size': 16, 'epochs': 22, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.14561457009902096, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.8449339989982713.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:04,274] Trial 2 finished with value: 0.8499184075743622 and parameters: {'learning_rate': 0.00023345864076016249, 'batch_size': 16, 'epochs': 34, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.08526206184364576, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:08,639] Trial 3 finished with value: 0.8416743412017516 and parameters: {'learning_rate': 8.200518402245828e-05, 'batch_size': 32, 'epochs': 15, 'n_layers': 2, 'n_units': 32, 'dropout_rate': 0.45466020103939103, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:21,357] Trial 4 finished with value: 0.8433385035464431 and parameters: {'learning_rate': 0.00043664735929796326, 'batch_size': 32, 'epochs': 48, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.4609371175115584, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:27,206] Trial 5 finished with value: 0.8459195708723118 and parameters: {'learning_rate': 0.00014656553886225324, 'batch_size': 32, 'epochs': 21, 'n_layers': 2, 'n_units': 32, 'dropout_rate': 0.40109849037701983, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:42,915] Trial 6 finished with value: 0.8414198697752573 and parameters: {'learning_rate': 1.0388823104027935e-05, 'batch_size': 16, 'epochs': 41, 'n_layers': 1, 'n_units': 64, 'dropout_rate': 0.05793452976256486, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:54,153] Trial 7 finished with value: 0.8403535133213772 and parameters: {'learning_rate': 8.569331925053983e-05, 'batch_size': 32, 'epochs': 46, 'n_layers': 2, 'n_units': 32, 'dropout_rate': 0.3566223936114975, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:30:59,456] Trial 8 finished with value: 0.8433708173783788 and parameters: {'learning_rate': 0.0003699972431463808, 'batch_size': 16, 'epochs': 11, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.2542853455823514, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:12,768] Trial 9 finished with value: 0.8470869080509912 and parameters: {'learning_rate': 4.857295179217165e-05, 'batch_size': 32, 'epochs': 48, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.43573029509385885, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:18,593] Trial 10 finished with value: 0.8480199699481363 and parameters: {'learning_rate': 0.002146403547714585, 'batch_size': 64, 'epochs': 33, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.01936259998059142, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:24,444] Trial 11 finished with value: 0.8486904819608033 and parameters: {'learning_rate': 0.002497815168647236, 'batch_size': 64, 'epochs': 35, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.015368433217561676, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:30,281] Trial 12 finished with value: 0.8435848965149533 and parameters: {'learning_rate': 0.009301047080298521, 'batch_size': 64, 'epochs': 35, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.12040396875045506, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:34,980] Trial 13 finished with value: 0.8496962499798039 and parameters: {'learning_rate': 0.0012690764532532696, 'batch_size': 64, 'epochs': 27, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.1975018307236228, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:39,485] Trial 14 finished with value: 0.849163071752864 and parameters: {'learning_rate': 0.0008678047296390247, 'batch_size': 64, 'epochs': 26, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.20457258282770732, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:50,864] Trial 15 finished with value: 0.847923028452329 and parameters: {'learning_rate': 0.0007853920890190521, 'batch_size': 16, 'epochs': 28, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.2774792196989158, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:31:57,450] Trial 16 finished with value: 0.8404666117331524 and parameters: {'learning_rate': 2.418092849725909e-05, 'batch_size': 64, 'epochs': 40, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.12538440298125225, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:08,636] Trial 17 finished with value: 0.8443846638553633 and parameters: {'learning_rate': 0.0008806919657997668, 'batch_size': 16, 'epochs': 24, 'n_layers': 2, 'n_units': 128, 'dropout_rate': 0.19400556986335143, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:15,068] Trial 18 finished with value: 0.847543340927084 and parameters: {'learning_rate': 0.00025806884477818466, 'batch_size': 64, 'epochs': 31, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.31370991330748377, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:30,761] Trial 19 finished with value: 0.813298757533162 and parameters: {'learning_rate': 0.009788521552968566, 'batch_size': 16, 'epochs': 39, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.07897565003002799, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:36,367] Trial 20 finished with value: 0.8406039455188793 and parameters: {'learning_rate': 0.004353097843906357, 'batch_size': 64, 'epochs': 29, 'n_layers': 2, 'n_units': 96, 'dropout_rate': 0.2051102112946549, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:41,107] Trial 21 finished with value: 0.8495750731100449 and parameters: {'learning_rate': 0.0010778668261656613, 'batch_size': 64, 'epochs': 27, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.1948905935501211, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:44,856] Trial 22 finished with value: 0.8490903656310085 and parameters: {'learning_rate': 0.0012424814685740775, 'batch_size': 64, 'epochs': 20, 'n_layers': 1, 'n_units': 64, 'dropout_rate': 0.16300279988054436, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:49,339] Trial 23 finished with value: 0.8486177758389479 and parameters: {'learning_rate': 0.0005329482461277144, 'batch_size': 64, 'epochs': 25, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.07932639773094291, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:32:55,424] Trial 24 finished with value: 0.8469132212043365 and parameters: {'learning_rate': 0.00019507359024560986, 'batch_size': 64, 'epochs': 37, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.29274728416067275, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:33:00,738] Trial 25 finished with value: 0.8467637697316337 and parameters: {'learning_rate': 0.005146364646711955, 'batch_size': 64, 'epochs': 31, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.23292371571366258, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:33:17,271] Trial 26 finished with value: 0.8335797263018435 and parameters: {'learning_rate': 0.0016991046199400022, 'batch_size': 16, 'epochs': 44, 'n_layers': 1, 'n_units': 64, 'dropout_rate': 0.17213189957459035, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:33:20,823] Trial 27 finished with value: 0.8485248735721325 and parameters: {'learning_rate': 0.000606514058090697, 'batch_size': 64, 'epochs': 18, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.10775445381745677, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:33:26,205] Trial 28 finished with value: 0.8489166787843536 and parameters: {'learning_rate': 0.0012882687203160169, 'batch_size': 64, 'epochs': 27, 'n_layers': 2, 'n_units': 128, 'dropout_rate': 0.34002422398680154, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8499184075743622.\n",
      "/tmp/ipykernel_178822/2772100943.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:33:39,013] Trial 29 finished with value: 0.8458024332315447 and parameters: {'learning_rate': 0.00029461426092931647, 'batch_size': 16, 'epochs': 33, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.2372276176062828, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8499184075743622.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42), storage=\"sqlite:///db.sqlite3\", study_name='test_seed')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8a3853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "AUC: 0.8499184075743622\n",
      "Params:\n",
      "  learning_rate: 0.00023345864076016249\n",
      "  batch_size: 16\n",
      "  epochs: 34\n",
      "  n_layers: 1\n",
      "  n_units: 96\n",
      "  dropout_rate: 0.08526206184364576\n",
      "  activation: tanh\n",
      "  optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"AUC: {trial.value}\")\n",
    "print(\"Params:\")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    epochs = trial.suggest_int('epochs', 10, 50)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    n_units = trial.suggest_int('n_units', 32, 128, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
    "\n",
    "    # Optimizer mapping\n",
    "    optimizer = {\n",
    "        'adam': Adam(learning_rate=learning_rate),\n",
    "        'rmsprop': RMSprop(learning_rate=learning_rate)\n",
    "    }[optimizer_name]\n",
    "\n",
    "    # Compute class weights\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train_vector),\n",
    "        y=y_train_vector\n",
    "    )\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "    # Build model\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Input(shape=(X_train_dense.shape[1],)))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(Dense(n_units, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['recall']\n",
    "    )\n",
    "\n",
    "    # Early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='recall', mode='max', patience=5,\n",
    "        restore_best_weights=True, verbose=0\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    model.fit(\n",
    "        X_train_dense, y_train_vector,\n",
    "        validation_data=(X_val_dense, y_val_vector),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        callbacks=[early_stop],\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred_proba = model.predict(X_val_dense)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    recall = recall_score(y_val_vector, y_pred)\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4023eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:06,948] A new study created in RDB with name: maximize_recall1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:13,317] Trial 0 finished with value: 0.7859531772575251 and parameters: {'learning_rate': 0.0001329291894316216, 'batch_size': 16, 'epochs': 16, 'n_layers': 1, 'n_units': 32, 'dropout_rate': 0.4330880728874676, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.7859531772575251.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:22,535] Trial 1 finished with value: 0.725752508361204 and parameters: {'learning_rate': 0.00314288089084011, 'batch_size': 16, 'epochs': 22, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.14561457009902096, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.7859531772575251.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:35,784] Trial 2 finished with value: 0.8093645484949833 and parameters: {'learning_rate': 0.00023345864076016249, 'batch_size': 16, 'epochs': 34, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.08526206184364576, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:39,940] Trial 3 finished with value: 0.782608695652174 and parameters: {'learning_rate': 8.200518402245828e-05, 'batch_size': 32, 'epochs': 15, 'n_layers': 2, 'n_units': 32, 'dropout_rate': 0.45466020103939103, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:52,363] Trial 4 finished with value: 0.7692307692307693 and parameters: {'learning_rate': 0.00043664735929796326, 'batch_size': 32, 'epochs': 48, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.4609371175115584, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:45:58,036] Trial 5 finished with value: 0.7892976588628763 and parameters: {'learning_rate': 0.00014656553886225324, 'batch_size': 32, 'epochs': 21, 'n_layers': 2, 'n_units': 32, 'dropout_rate': 0.40109849037701983, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:46:13,400] Trial 6 finished with value: 0.7892976588628763 and parameters: {'learning_rate': 1.0388823104027935e-05, 'batch_size': 16, 'epochs': 41, 'n_layers': 1, 'n_units': 64, 'dropout_rate': 0.05793452976256486, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:46:25,054] Trial 7 finished with value: 0.7993311036789298 and parameters: {'learning_rate': 8.569331925053983e-05, 'batch_size': 32, 'epochs': 46, 'n_layers': 2, 'n_units': 32, 'dropout_rate': 0.3566223936114975, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:46:30,213] Trial 8 finished with value: 0.7993311036789298 and parameters: {'learning_rate': 0.0003699972431463808, 'batch_size': 16, 'epochs': 11, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.2542853455823514, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:46:43,159] Trial 9 finished with value: 0.802675585284281 and parameters: {'learning_rate': 4.857295179217165e-05, 'batch_size': 32, 'epochs': 48, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.43573029509385885, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:46:48,624] Trial 10 finished with value: 0.7993311036789298 and parameters: {'learning_rate': 0.002146403547714585, 'batch_size': 64, 'epochs': 33, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.01936259998059142, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:46:55,795] Trial 11 finished with value: 0.7926421404682275 and parameters: {'learning_rate': 1.9360883556873957e-05, 'batch_size': 64, 'epochs': 36, 'n_layers': 3, 'n_units': 128, 'dropout_rate': 0.2706771098509304, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:47:08,756] Trial 12 finished with value: 0.7892976588628763 and parameters: {'learning_rate': 3.0210752570094913e-05, 'batch_size': 16, 'epochs': 28, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.16026723128408465, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:47:17,985] Trial 13 finished with value: 0.7959866220735786 and parameters: {'learning_rate': 0.0007637106304017796, 'batch_size': 32, 'epochs': 40, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.3304278626461433, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:47:27,112] Trial 14 finished with value: 0.782608695652174 and parameters: {'learning_rate': 4.720845304099489e-05, 'batch_size': 64, 'epochs': 50, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.15172315044427895, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:47:35,554] Trial 15 finished with value: 0.7391304347826086 and parameters: {'learning_rate': 0.0007820833328059753, 'batch_size': 32, 'epochs': 28, 'n_layers': 3, 'n_units': 128, 'dropout_rate': 0.0836460058929473, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:47:51,422] Trial 16 finished with value: 0.7190635451505016 and parameters: {'learning_rate': 0.006496560363487984, 'batch_size': 16, 'epochs': 42, 'n_layers': 1, 'n_units': 96, 'dropout_rate': 0.20946317915338447, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:48:05,927] Trial 17 finished with value: 0.7759197324414716 and parameters: {'learning_rate': 0.00021851513767514656, 'batch_size': 16, 'epochs': 35, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.3090721123586372, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:48:16,074] Trial 18 finished with value: 0.7792642140468228 and parameters: {'learning_rate': 4.645570665778964e-05, 'batch_size': 32, 'epochs': 44, 'n_layers': 1, 'n_units': 128, 'dropout_rate': 0.214663742172685, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:48:21,928] Trial 19 finished with value: 0.7759197324414716 and parameters: {'learning_rate': 1.1681787874735517e-05, 'batch_size': 64, 'epochs': 25, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.3730691549031338, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:48:38,113] Trial 20 finished with value: 0.782608695652174 and parameters: {'learning_rate': 0.0011022014947457692, 'batch_size': 16, 'epochs': 39, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.4893665719121502, 'activation': 'tanh', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:48:49,859] Trial 21 finished with value: 0.7993311036789298 and parameters: {'learning_rate': 7.882156351202823e-05, 'batch_size': 32, 'epochs': 46, 'n_layers': 2, 'n_units': 96, 'dropout_rate': 0.360280483739408, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:01,228] Trial 22 finished with value: 0.7959866220735786 and parameters: {'learning_rate': 9.085817036149874e-05, 'batch_size': 32, 'epochs': 50, 'n_layers': 1, 'n_units': 32, 'dropout_rate': 0.39649739976798554, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:12,402] Trial 23 finished with value: 0.7926421404682275 and parameters: {'learning_rate': 0.0002905271522062731, 'batch_size': 32, 'epochs': 45, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.3056590000771481, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:21,570] Trial 24 finished with value: 0.7926421404682275 and parameters: {'learning_rate': 4.2840452341302154e-05, 'batch_size': 32, 'epochs': 32, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.10355702478552717, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:31,772] Trial 25 finished with value: 0.7859531772575251 and parameters: {'learning_rate': 0.0001728930724223375, 'batch_size': 32, 'epochs': 38, 'n_layers': 2, 'n_units': 128, 'dropout_rate': 0.4259371636488448, 'activation': 'relu', 'optimizer': 'adam'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:42,979] Trial 26 finished with value: 0.802675585284281 and parameters: {'learning_rate': 2.4472472840492582e-05, 'batch_size': 32, 'epochs': 47, 'n_layers': 2, 'n_units': 64, 'dropout_rate': 0.4932992544973801, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:52,416] Trial 27 finished with value: 0.7926421404682275 and parameters: {'learning_rate': 2.249166001803003e-05, 'batch_size': 32, 'epochs': 42, 'n_layers': 1, 'n_units': 64, 'dropout_rate': 0.4949267329198006, 'activation': 'relu', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:49:59,066] Trial 28 finished with value: 0.7558528428093646 and parameters: {'learning_rate': 1.905259069825371e-05, 'batch_size': 64, 'epochs': 36, 'n_layers': 3, 'n_units': 96, 'dropout_rate': 0.49548883189341014, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n",
      "/tmp/ipykernel_178822/2120121295.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "/home/utilisateur/Documents/deeplearning_brief/DeepLearning-Project/.venv/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,recall,val_loss,val_recall\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 09:50:17,212] Trial 29 finished with value: 0.7859531772575251 and parameters: {'learning_rate': 3.047732817556332e-05, 'batch_size': 16, 'epochs': 49, 'n_layers': 1, 'n_units': 64, 'dropout_rate': 0.0045332811460873645, 'activation': 'tanh', 'optimizer': 'rmsprop'}. Best is trial 2 with value: 0.8093645484949833.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42), storage=\"sqlite:///db.sqlite3\", study_name='maximize_recall1')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd131f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
